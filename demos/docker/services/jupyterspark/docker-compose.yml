version: '3'
services:
# Set up NameNode and Spark Master
  sparkmaster:
    image: rmuresano/bdaassparkmaster:0_0_1
    hostname: sparkmaster
    container_name: sparkmaster
    environment:
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - HDFS_NAMENODE_METADATA_PORT=9000
      - HDFS_CLUSTER_NAME=HDFS_TEST
      - HDFS_NAMENODE_WEBUI_PORT=50070
      - HDFS_REPLICATION_FACTOR=1
      - HDFS=YES
    ports:
      - "8080:8080" #Web Interface Master
      - "7077:7077" #Master Port
      - "9000:9000" # HDFS PORT
      - "50070:50070" # WEB NameNode Int
    volumes:
      - hdfs-name-node:/hdfsdata/nameNode/
# Setup the Worker Node 1.
  sparkworker:
    image: rmuresano/bdaassparkworker:0_0_1
    hostname: sparkworker
    depends_on:
      - sparkmaster
    links:
      - sparkmaster
    environment:
      - SPARK_MASTER_HOSTNAME=sparkmaster
      - SPARK_MASTER_PORT=7077
      - HDFS_NAMENODE_HOSTNAME=sparkmaster
      - HDFS_NAMENODE_METADATA_PORT=9000
      - HDFS_REPLICATION_FACTOR=1
      - HDFS_DATANODE_WEBUI_PORT=50075
      - SPARK_WORKER_WEBUI_PORT=8081
      - HDFS_NAMENODE_WEBUI_PORT=50070
      - HDFS=YES

    ports:
      - "8081-8090:8081"
  jupyter:
    image: rmuresano/bdaasjupyter:0_0_1
    hostname: jupyter
    container_name: jupyter
    depends_on:
      - sparkmaster
    links:
      - sparkmaster
    environment:
      - STANDALONE=NO
      - JUPYTERPORT=8900
      - HDFS=YES
      - HDFS_NAMENODE_HOSTNAME=sparkmaster
      - HDFS_DATANODE_WEBUI_PORT=50075
      - HDFS_NAMENODE_METADATA_PORT=9000
      - HDFS_REPLICATION_FACTOR=1
      - SPARK_MASTER_HOSTNAME=sparkmaster
      - SPARK_MASTER_PORT=7077
    ports:
      - "8900:8900" # WEB interface JupyterLab
    volumes:
      - jupyter-vol:/data/jupyter/

volumes:
  jupyter-vol:
  hdfs-name-node:
#  hdfs-data-node:
